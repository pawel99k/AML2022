{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bearing-qualification",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import optimizers\n",
    "import measures\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.datasets import make_moons\n",
    "X, y = make_moons()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "framed-chaos",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression:\n",
    "    def __init__(self, optimization, **kwargs):\n",
    "        self.optimization = optimization\n",
    "        self.kwargs=kwargs\n",
    "        self.losses = None\n",
    "        self.is_trained = False\n",
    "        self.__is_optimization_known(optimization)\n",
    "        if optimization == 'Gradient Descent':\n",
    "            self.__optimizer = optimizers.GradientDescent(**self.kwargs)\n",
    "        elif optimization == 'Stochastic Gradient Descent':\n",
    "            self.kwargs['batch_size'] = 1\n",
    "            self.__optimizer = optimizers.GradientDescent(**self.kwargs)\n",
    "        elif optimization == 'Iterative Reweighted Least Squares':\n",
    "            self.__optimizer = optimizers.IRLS(**self.kwargs)\n",
    "        elif optimization == 'Adaptive Moment Estimation':\n",
    "            self.__optimizer = optimizers.ADAM(**self.kwargs)\n",
    "            \n",
    "    @staticmethod\n",
    "    def __is_optimization_known(o):\n",
    "        if o not in ['Gradient Descent', 'Stochastic Gradient Descent',\n",
    "                     'Iterative Reweighted Least Squares', 'Adaptive Moment Estimation']:\n",
    "            raise ValueError(f'Unknown optimization {o}')\n",
    "\n",
    "    def train(self, X, y):\n",
    "        #todo: check the dimensions?\n",
    "        self.__optimizer.train(X, y)\n",
    "        \n",
    "    def predict(self, X):\n",
    "        return self.__optimizer.predict(X)\n",
    "    \n",
    "    def get_optimizer_training_losses(self):\n",
    "        return self.__optimizer.losses\n",
    "    def get_optimizer_training_w(self):\n",
    "        return self.__optimizer.w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loved-microphone",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_gd = LogisticRegression(optimization='Gradient Descent', learning_rate=0.01, epochs=50, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "million-reflection",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_gd.train(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adjustable-vanilla",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_sgd = LogisticRegression(optimization='Stochastic Gradient Descent', learning_rate=0.01, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complete-shower",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_sgd.train(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4078cbe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lr_irls = LogisticRegression(optimization='Iterative Reweighted Least Squares', epochs=50)\n",
    "lr_irls.train(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5895f457",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lr_adam = LogisticRegression(optimization='Adaptive Moment Estimation',\n",
    "                             epochs=50,\n",
    "                             learning_rate=0.01,\n",
    "                             beta_1=0.9,\n",
    "                             beta_2=0.99,\n",
    "                             epsilon=1e-8\n",
    "                            )\n",
    "lr_adam.train(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suspended-metallic",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "l_gd = lr_gd.get_optimizer_training_losses()\n",
    "l_sgd = lr_sgd.get_optimizer_training_losses()\n",
    "l_irls=lr_irls.get_optimizer_training_losses()\n",
    "l_adam=lr_adam.get_optimizer_training_losses()\n",
    "plt.plot(range(len(l_gd)), l_gd, label='Gradient descent')\n",
    "plt.plot(range(len(l_sgd)), l_sgd, label='SGD')\n",
    "plt.plot(range(len(l_irls)), l_irls, label='IRLS')\n",
    "plt.plot(range(len(l_adam)), l_adam, label='ADAM')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Iteration')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "temporal-laugh",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "p_gd = lr_gd.predict(X)\n",
    "p_sgd = lr_sgd.predict(X)\n",
    "p_irls=lr_irls.predict(X)\n",
    "p_adam=lr_adam.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "established-folks",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.scatter(*X.T, c=y)\n",
    "plt.title('Original data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "threaded-theta",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"accuracy: \",np.mean(p_gd==y))\n",
    "plt.scatter(*X.T, c=p_gd)\n",
    "plt.title('Predictions of GD')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impressive-despite",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"accuracy: \",np.mean(p_sgd==y))\n",
    "plt.scatter(*X.T, c=p_sgd)\n",
    "plt.title('Predictions of SGD')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4824e8d8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"accuracy: \",np.mean(p_irls==y))\n",
    "plt.scatter(*X.T, c=p_irls)\n",
    "plt.title('Predictions of IRLS')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19bd9f33",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"accuracy: \",np.mean(p_adam==y))\n",
    "plt.scatter(*X.T, c=p_adam)\n",
    "plt.title('Predictions of ADAM')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "982eb404",
   "metadata": {},
   "source": [
    "### Tests on retinopathy dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc72cc6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import OneHotEncoder \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.impute import SimpleImputer\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from scipy.io import arff\n",
    "\n",
    "class ReduceVIF(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, thresh=5, impute=True, impute_strategy='median'):\n",
    "        # From looking at documentation, values between 5 and 10 are \"okay\".\n",
    "        # Above 10 is too high and so should be removed.\n",
    "        self.thresh = thresh\n",
    "        \n",
    "        # The statsmodel function will fail with NaN values, as such we have to impute them.\n",
    "        # By default we impute using the median value.\n",
    "        # This imputation could be taken out and added as part of an sklearn Pipeline.\n",
    "        if impute:\n",
    "            self.imputer = SimpleImputer(strategy=impute_strategy)\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        print('ReduceVIF fit')\n",
    "        if hasattr(self, 'imputer'):\n",
    "            self.imputer.fit(X)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        print('ReduceVIF transform')\n",
    "        columns = X.columns.tolist()\n",
    "        if hasattr(self, 'imputer'):\n",
    "            X = pd.DataFrame(self.imputer.transform(X), columns=columns)\n",
    "        return ReduceVIF.calculate_vif(X, self.thresh)\n",
    "\n",
    "    @staticmethod\n",
    "    def calculate_vif(X, thresh):\n",
    "        dropped=True\n",
    "        while dropped:\n",
    "            variables = X.columns\n",
    "            dropped = False\n",
    "            vif = [variance_inflation_factor(X[variables].values, X.columns.get_loc(var)) for var in X.columns]\n",
    "            \n",
    "            max_vif = max(vif)\n",
    "            if max_vif > thresh:\n",
    "                maxloc = vif.index(max_vif)\n",
    "                print(f'Dropping {X.columns[maxloc]} with vif={max_vif}')\n",
    "                X = X.drop([X.columns.tolist()[maxloc]], axis=1)\n",
    "                dropped=True\n",
    "        print(X.shape[1],\" features left in dataset\")\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1303b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = arff.loadarff('data/messidor_features.arff')\n",
    "retinopathy_df = pd.DataFrame(data[0])\n",
    "retinopathy_df.head()\n",
    "retinopathy_df.drop(columns='Class',inplace=True)\n",
    "X_retinopathy=retinopathy_df.drop(columns='18')\n",
    "y_retinopathy=retinopathy_df['18']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33912643",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Mult_Coll = ReduceVIF()\n",
    "\n",
    "X_retinopathy_clean = Mult_Coll.fit_transform(X_retinopathy)\n",
    "X_train, X_test, y_train, y_test=train_test_split(X_retinopathy_clean.to_numpy(dtype=\"float64\"),y_retinopathy.to_numpy(dtype=\"int32\"),test_size=0.2)\n",
    "\n",
    "model = LogisticRegression(optimization='Adaptive Moment Estimation',\n",
    "                             epochs=5000,\n",
    "                             learning_rate=0.01,\n",
    "                             beta_1=0.9,\n",
    "                             beta_2=0.99,\n",
    "                             epsilon=1e-8\n",
    "                            )\n",
    "model.train(X_train, y_train)\n",
    "print(X_train.shape[1])\n",
    "p_adam=model.predict(X_test)\n",
    "np.mean(p_adam==y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1787f5fa",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "l_adam=model.get_optimizer_training_losses()\n",
    "\n",
    "plt.plot(range(len(l_adam)), l_adam, label='ADAM')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Iteration')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
